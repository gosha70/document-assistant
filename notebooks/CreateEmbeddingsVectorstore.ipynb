{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOT9NbiooYFkG6yCO0BT2u9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Create Embeddings Vectorstore\n","\n","This is a Collab script creates a [Chroma](https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html)  vector store from the specified **zip** file, which includes `JSON` files with splits of unstructured documents.\n","\n","Use the following [script](https://github.com/gosha70/document-assistant/blob/main/embeddings/document_loader.py) to scan and proocess local documents. After the cloning the [document-assistant](https://github.com/gosha70/document-assistant), navigate into the cloned repo:\n","\n","```\n","> python3 -m embeddings.document_loader --dir_path DOCUMENT_FOLDER --file_type FILE_TYPE --file_type FILE_NAME_PATTERN --persist_directory OUTPUT_FOLDER\n","```\n","\n","Where:\n","\n","\n","* `--dir_path`- (optional) the root directory where to look for documents. The default is `\".\"`\n","* `--file_type`- the list of file extensions:\n"," * `md`\n"," * `java`\n"," * `xml`\n"," * `html`\n"," * `pdf`\n","\n","* `--file_patterns` - (optional) file name patterns for each file type; for example: `--file_patterns \"java:**/*Function.java\" \"java:**/*Api*\"`\n","\n","\n","* `--persist_directory` - (optional) the path to the directory where unstructured document splits are saved."],"metadata":{"id":"ZWaCbmCLclrq"}},{"cell_type":"markdown","source":["### Installation\n","---\n","Install required python libraries:\n","\n","\n","1.   [LangChain](https://python.langchain.com/docs/modules/chains/foundational/llm_chain)\n","\n","2. [ChromaDB](https://docs.trychroma.com/)\n","\n","3. [Huggingface](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceInstructEmbeddings.html)\n","\n","\n"],"metadata":{"id":"LgnHjQWFbk-x"}},{"cell_type":"code","source":["# Install lingchain and embedding libraries\n","!pip install langchain transformers tqdm sentence_transformers InstructorEmbedding huggingface huggingface_hub chromadb"],"metadata":{"id":"rSr7otKWWwvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Map Google Drive\n","---\n","Map to Google Drive where a zip file with Documents splits is located"],"metadata":{"id":"UHcy_D2MbMLC"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"r1c24yFQbZcx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Unzip Documents\n","\n","Set the following variables:\n","\n","\n","*   `zip_path`: the full path to the zip file in the mounted Google Drive\n","*   `extract_dir`: the full path to the directory where extracted files are saved\n","\n"],"metadata":{"id":"3oI1Xu3ddmQc"}},{"cell_type":"code","source":["import zipfile\n","import os\n","# Specify a full path to the zip file:\n","zip_path = '/content/drive/MyDrive/DOCS_ZIP.zip'\n","\n","# Specify a directory to extract the zip file to:\n","extract_dir = '/content/drive/MyDrive/UNZIP_FOLDER'\n","\n","# Specify a directory to cache the embedding data.\n","# Comment out this lien. if you want to disable the Transformer Cache.\n","os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/TRANSFORMER_CACHE'\n","\n","def unzip_documents(zip_file, unzip_folder):\n","  # Create the directory if it doesn't exist\n","  os.makedirs(extract_dir, exist_ok=True)\n","\n","  # Open the zip file\n","  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","      # Extract all the contents into the directory\n","      zip_ref.extractall(extract_dir)\n","\n","# Unzip documents.\n","# If you run the script a few times, - comment out this line after the first run.\n","unzip_documents(zip_file=zip_path, unzip_folder=extract_dir)"],"metadata":{"id":"H5Xm3bWwd1Y2","executionInfo":{"status":"ok","timestamp":1703377479587,"user_tz":300,"elapsed":7,"user":{"displayName":"George Ivan","userId":"15934351572926549385"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## JSON to Document\n","\n","The conversion utility to convert the textual presentation of `Document` stored in a loaded **JSON** into in the in-memory `Document`.\n","\n","Here is the example of *jsonified* `Document`:\n","```\n","{\n","    \"lc\": 1,\n","    \"type\": \"constructor\",\n","    \"id\": [\n","        \"langchain_core\",\n","        \"documents\",\n","        \"base\",\n","        \"Document\"\n","    ],\n","    \"kwargs\": {\n","        \"page_content\": \"public class Main {}\\n\\n}\",\n","        \"metadata\": {\n","            \"source\": \"Main.java\"\n","        }\n","    }\n","}\n","```"],"metadata":{"id":"p6rn0RNUexkf"}},{"cell_type":"code","source":["import json\n","from langchain_core.documents import Document\n","\n","def load_document(file) -> Document:\n","    \"\"\"\n","    Create a Document from the specified JSON file.\n","\n","    Parameters:\n","    - file (File): the JSON file\n","\n","    Returns (Document)\n","    \"\"\"\n","    try:\n","        # Read and process the content as JSON\n","        json_content = file.read()\n","\n","        # Parse the JSON content\n","        data = json.loads(json_content)\n","\n","        # Access the \"page_content\" field\n","        page_content = data['kwargs']['page_content']\n","\n","        # Access the \"metadata\" field\n","        metadata = data['kwargs']['metadata']\n","\n","        # Transform the data into a langchain_core.documents.Document\n","        # Assuming the JSON structure fits the Document's requirements\n","        return Document(page_content=page_content, metadata=metadata)\n","    except Exception as error:\n","        print(f\"File {file} is not a valid JSON: {str(error)}\")\n","\n","    return None"],"metadata":{"id":"3w0KPdc_bURY","executionInfo":{"status":"ok","timestamp":1703377479745,"user_tz":300,"elapsed":164,"user":{"displayName":"George Ivan","userId":"15934351572926549385"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Create Embedding LLM\n","\n","1. Update `EMBEDDING_KWARGS` the device type based on the selected runtime environment: `cuda` or `cpu`\n","\n","2. Update `DEFAULT_MODEL_NAME` with the model name of embedding LLM. The choosen model must correspond to a model will be use later in a runtime Application. Both models must have the same dimensionality: the number of dimensions in which the vector representation of a word is defined; the total number of features that are encoded in the vector representation.\n"],"metadata":{"id":"ZcycLUlvfpbM"}},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceInstructEmbeddings\n","from tqdm.auto import tqdm\n","\n","# You have to choose GPU in order to use CUDA\n","EMBEDDING_KWARGS = {'device': 'cpu'} # 'cuda' or 'cpu'\n","ENCODE_KWARG = {'normalize_embeddings': True}\n","\n","def create_embedding(model_name):\n","    return HuggingFaceInstructEmbeddings(\n","        model_name=model_name,\n","        model_kwargs=EMBEDDING_KWARGS,\n","        encode_kwargs=ENCODE_KWARG\n","    )\n","\n","DEFAULT_MODEL_NAME = \"hkunlp/instructor-large\"\n","\n","# Create Embedding LLM\n","embedding = create_embedding(model_name=DEFAULT_MODEL_NAME)"],"metadata":{"id":"WhUWHe_EfqFH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create/Update Chroma Vectorstore\n","\n","\n","Customize the following variables:\n","*   `persist_directory`: the folder where the **Chroma** vectorstore is located\n","*   `collection_name`: the name of the **Chroma** vectorstore\n","\n"],"metadata":{"id":"BKk2K4rxfq_u"}},{"cell_type":"code","source":["import chromadb\n","from chromadb.config import Settings\n","from langchain.vectorstores import Chroma\n","\n","def create_vectorestore(embedding, documents) -> Chroma:\n","  # Specify the location in Google Drive where the new Chroma vectorstore is saved.\n","  persist_directory = '/content/drive/MyDrive/CHROMA_DB/'\n","  # Specify the name of the new Chroma vectorstore\n","  collection_name=\"CHROMA_NAME\"\n","  print(f\"Creating the embedding vectorstore with {embedding}\\n with {len(documents)} document splits ...\")\n","  docs_db = Chroma.from_documents(\n","      documents=documents,\n","      collection_name=collection_name\n","      embedding=embedding,\n","      persist_directory=persist_directory\n","  )\n","\n","  # Save the Chroma database after processing each chunk\n","  print(f\"Saving the Chroma vectorstore with {len(documents)} documents  ...\")\n","  docs_db.persist()\n","\n","  return docs_db\n","\n","def process_documents_in_chunks(embedding, file_paths, chunk_size) -> Chroma:\n","  docs_db = None\n","  total_count = len(file_paths)\n","  # Process in chunks\n","  for i in range(0, len(file_paths), chunk_size):\n","      chunk = file_paths[i:i + chunk_size]\n","      documents = []\n","\n","      # Process each file in the chunk\n","      for file_path in chunk:\n","          with open(file_path, 'r') as file:\n","              doc = load_document(file)\n","              if doc is not None:\n","                  documents.append(doc)\n","\n","      batch_id = f\"{i // chunk_size + 1}/{total_count // chunk_size + 1}\"\n","      print(f\"Processing the batch {batch_id}: {len(documents)} documents\")\n","      if documents:\n","          if docs_db is None:\n","            docs_db = create_vectorestore(embedding=embedding, documents=documents)\n","          else:\n","            print(f\"Updating the embedding vectorstore with {len(documents)} document splits ...\")\n","            docs_db.add_documents(documents=documents)\n","            # Save the Chroma database after processing each chunk\n","            print(f\"Finished the batch {batch_id}.\")\n","\n","  docs_db.persist()\n","  return docs_db"],"metadata":{"id":"ite96x6XfPEe","executionInfo":{"status":"ok","timestamp":1703377491592,"user_tz":300,"elapsed":542,"user":{"displayName":"George Ivan","userId":"15934351572926549385"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Process All Documents"],"metadata":{"id":"Y92JKE-cfOh2"}},{"cell_type":"code","source":["CHUNK_SIZE = 1000  # Number of files to process at a time\n","\n","# Collect all file paths\n","file_paths = []\n","for dirpath, dirnames, filenames in os.walk(extract_dir):\n","    for file_name in filenames:\n","        full_path = os.path.join(dirpath, file_name)\n","        file_paths.append(full_path)\n","\n","filesCount = len(file_paths)\n","print(f\"Found {filesCount} files will be processed in {CHUNK_SIZE} batches ...\")"],"metadata":{"id":"k4o5bRM0dt43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if filesCount > 0:\n","  chroma_db = process_documents_in_chunks(embedding, file_paths, CHUNK_SIZE)\n","  dic = chroma_db.get()[\"ids\"]\n","  print(f\"Finished the creation of the Chroma vectorstore with {len(dic)} documents:\\n {chroma_db}\")\n","else:\n","  print(\"ERROR: Cannot create the Chroma vectorstore without documents.\")"],"metadata":{"id":"cWZqkKmwzBPL"},"execution_count":null,"outputs":[]}]}